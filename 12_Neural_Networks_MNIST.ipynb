{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "wcU8F2Kq5WD3",
   "metadata": {
    "id": "wcU8F2Kq5WD3"
   },
   "source": [
    "# Neuronale Netze (Neural Networks)\n",
    "\n",
    "Als erstes müssen wir die notwendingen Pakete in Google Colab installieren. Das machen wir im ersten Codeblock.\n",
    "\n",
    "Achtung! Der erste Codeblock dauert etwa 5-7 Minuten, um ausgeführt zu werden. Leider müssen wir den Code **jedes Mal neu** ausführen, da die Colab-Laufzeiten temporärer Natur sind (für eine permanente Lösung müssten wir Geld bezahlen). Daher führt den ersten Code-Block für die Installation der notwendigen Pakete gerne am Anfang der Übung einmal aus, und lest dann schon mal weiter!\n",
    "\n",
    "Wir brauchen die Deep Learning Architekturen `keras` und `tensorflow`. Außerdem wichtig ist das Paket `magick`, mit welchem wir am Ende der Übung eigene Bilder in R hochladen und verarbeiten können. `magick` braucht einige Systembefehle, um installiert werden zu können.\n",
    "\n",
    "> Systembefehle können in R mithilfe von `system()` direkt an die Konsole übergeben werden.\n",
    "\n",
    "Keine Sorge, ihr müsst bei dem folgenden Code nicht genau verstehen, was dort passiert. Hauptsache, alle notwendigen Pakete werden installiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e06ef-abd1-4115-a695-e426c262a51e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d29e06ef-abd1-4115-a695-e426c262a51e",
    "outputId": "73afb01c-7edd-4d5e-f29e-f0992bd5eee9"
   },
   "outputs": [],
   "source": [
    "# update system dependencies to install magick\n",
    "system('add-apt-repository -y ppa:cran/imagemagick')\n",
    "system('apt-get update')\n",
    "system(\"apt-get install libmagick++-dev\")\n",
    "\n",
    "# install magick and pacman\n",
    "install.packages(\"magick\")\n",
    "install.packages(\"pacman\")\n",
    "\n",
    "# load additional packages\n",
    "pacman::p_load(tidyverse, keras, tensorflow, magick)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PnkkmwY4KH8U",
   "metadata": {
    "id": "PnkkmwY4KH8U"
   },
   "source": [
    "## Einführung\n",
    "\n",
    "Neuronale Netzwerke bezeichnet eine Familie von Modellen künstlicher Intelligenz. Diese sind dem menschlichen Gehirn nachempfunden, um Informationen zu verarbeiten, Entscheidungen zu treffen oder Daten zu generieren.\n",
    "\n",
    "Wie der Name schon sagt, bestehen neuronale Netze aus sehr vielen kleinen Einheiten (nodes oder units, auch artificial neurons genannt), die über eine Vielzahl von Verbindungen miteinander verknüpft sind (angelehnt an die biologischen Neuronen im menschlichen Gehirn).\n",
    "\n",
    "Diese Netzwerke sind dadurch in der Lage, große Datenmengen zu verarbeiten und aus ihnen zu lernen. Durch ausgeklügelte Architektur und mit nicht linearen mathematischen Funktionen können künstliche neuronale Netze auf bestimmte Aufgaben trainiert werden.\n",
    "\n",
    "### Funktionsweise\n",
    "\n",
    "Neuronale Netze werden analog zu anderen **Supervised Learning** Algorithmen mit Trainingsdaten gefüttert und lernen so, bestimmte Muster und Entscheidungen nachzuahmen bzw. nachzumachen. Das Netzwerk wird durch sogenannte **backpropagation** trainiert - es macht eine Vorhersage, vergleich diese mit dem tatsächlichen Ergebnis aus den Trainingsdaten, und passt dann die Parameter des Modells an, um den Fehler zu minimieren. Mathematisch gesehen entspricht dieser Vorgang einem Optimierungsproblem, und in der Praxis wird dieser Schritt extrem oft wiederholt, bis der Fehler für den gesamten Trainingsdatensatz minimiert ist.\n",
    "\n",
    "Die **Struktur** neuronaler Netze ist vom menschlichen Gehirn inspiriert - sie bestehen aus einer Vielzahl an Einheiten, die miteinander verbunden sind. Die Einheiten sind in sogenannten **Layern** gruppiert. Die Verbindungen zwischen den einzelnen Einheiten (Neuronen) werden durch eine mathematische Funktion modelliert (**activation function**). Klassischerweise hat jede Verbindung eine **weight** und einen **bias**.\n",
    "\n",
    "Mittlerweile gibt es eine Vielzahl an verschiedenen Layerarten und Techniken, wie beispielsweise **Convolutional Neural Networks** (CNN: Bildverarbeitung, Computer Vision), **Recurrent Neural Networks** (RNN: sequenzielle Datenverarbeitung, wie z.B. Text oder Sprache), **Long Short-Termin Memory** (LSTM: Textgenerierung), **Transformer Networks** (Übersetzungen), **Generative Adversarial Networks** (GAN: Bildgenerierung), und viele weitere.\n",
    "\n",
    "In dieser Übung werden wir ein einfaches **Feedforward Neural Network** (FNN) trainieren.\n",
    "\n",
    "### Geschichte\n",
    "\n",
    "Erste Konzepte neuronaler Netze gehen zurück in die 1940er und 1950er Jahre, in denen das Verständnis des menschlichen Gehirns erste Konzepte mathematischer neuronaler Netze ermöglichte. Das erste tatsächliche neuronale Netz wurden in den späten 1950ern von Frank Rosenblatt als sogenanntes **perceptron** entwickelt, ein einfaches *two-layer learning network*. Die Entwicklung dieser Art von künstlicher Intelligenz ging durch Limitierung bzgl. Technologie und im Verständnis in den 70ern zurück (der sogenannte AI Winter). In den 80ern wurde dann das Konzept der **backpropagation** entwickelt, welches das \"Lernen\" der künstlichen neuronalen Netze ermöglichte. Doch erst in Kombination mit der Entwicklung immer leistungsstärkerer Computerchips und mit der zunehmenden Verfügbarkeit von Trainingsdaten setzten sich die künstlichen neuronalen Netze endgültig durch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uQB6LaDwXyjf",
   "metadata": {
    "id": "uQB6LaDwXyjf"
   },
   "source": [
    "## Tensorflow Playground\n",
    "\n",
    "Als Einstieg in die Technik neuronaler Netze können wir eine Lernumgebung von Tensorflow benutzen, die unter dem folgenden Link zu finden ist.\n",
    "\n",
    "https://playground.tensorflow.org/\n",
    "\n",
    "Hier könnt ihr an einem neuronalen Netzwerk in Echtzeit in eurem Browser herumspielen.\n",
    "\n",
    "Probiert doch mal ein paar verschiedene Knöpfe und Einstellungen aus, und findet heraus, was passiert. Don't worry, you can't break it! Falls etwas doch nicht mehr funktionieren sollte, könnt ihr die Seite einfach aktualisieren und neu aufrufen.\n",
    "\n",
    "Wir schauen uns das Modell dann auch nochmal gemeinsam an.\n",
    "\n",
    "Mögliche Fragen:\n",
    "* Was passiert, wenn zusätzliche Layer eingebaut werden?\n",
    "* Was passiert, wenn wir zusätzliche Neuronen hinzufügen?\n",
    "* Wie unterscheiden sich die Aktivierungsfunktionen der Neuronen (Activation) voneinander?\n",
    "* Wie sollte ein Modell optimalerweise eingestellt sein, um schnell zu lernen?\n",
    "\n",
    "Schafft ihr es, ein Modell zu trainieren, welches die Spirale abbilden kann?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jSMj_MUZ8mjw",
   "metadata": {
    "id": "jSMj_MUZ8mjw"
   },
   "source": [
    "## Deep Learning mit MNIST\n",
    "\n",
    "Ein weitverbreitetes und einfaches Beispiel für die Anwendung von neuronalen Netzen ist die [MNIST database of handwritten digits](http://yann.lecun.com/exdb/mnist/). Diese besteht aus tausenden von handgeschriebenen Ziffern, welche fotografiert und vereinheitlicht wurden. Mit der MNIST-Datenbank ist es möglich, ein neuronales Netz auf die Erkennung von weiteren handgeschriebenen Ziffern zu trainieren. Eine praktische Anwendung hat so ein neuronales Netz beispielsweise bei der Post, wenn es darum geht, die handgeschriebenen Postleitzahlen auf Briefen zu erkennen und computerlesbar zu machen.\n",
    "\n",
    "In dieser Übung werden wir ein einfaches neuronales Netz programmieren, welches genau diese Aufgabe (die Erkennung von handgeschriebenen Ziffern) übernehmen kann. Ein Großteil des Codes ist orientiert an:\n",
    "\n",
    "> Chollet, F., & Allaire, J. J. (2018). *Deep learning with R*. Shelter island. Manning Publications Co. Biometrics, 76, 361-362.\n",
    "\n",
    "Der Einfachheit halber werden wir in dieser Übung viele `base` Funktionen nutzen, weil die Implementation mit `tidyverse` teilweise etwas komplizierter wäre. Wir benutzen das Backend `tensorflow`, welches ursprünglich von Google in C++ und Python entwickelt wurde, und die Schnittstelle `keras` (in Python entwickelt). Beide Frameworks sind Open Source und gehören zu den weitverbreitesten Deep Learning Architekturen.\n",
    "\n",
    "> Weitere verbreitete Deep Learning Architekturen in R sind beispielsweise [Torch](https://torch.mlverse.org/), [Apache MXNet](https://mxnet.apache.org/versions/1.8.0/api/r) oder [h2o](https://cran.r-project.org/web/packages/h2o/index.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ILXl-LWk9HY2",
   "metadata": {
    "id": "ILXl-LWk9HY2"
   },
   "source": [
    "### MNIST laden und vorbereiten\n",
    "\n",
    "Der MNIST-Datensatz ist bereits in `keras` vorhanden. Wir können ihn komfortabel mit der Funktion `keras::dataset_mnist()` laden und in dem Objekt `mnist` speichern. Der Datensatz besteht aus 60.000 Trainings- und 10.000 Testbildern sowie deren zugehörigen Labels.\n",
    "\n",
    "> Der Datensatz ist bereits normalisiert sowie in Trainings- und Testdaten aufgeteilt - dadurch sparen wir uns hier etwas Arbeit.\n",
    "\n",
    "Da wir unser neuronales Netzwerk mit Supervised Learning trainieren wollen, haben wir wieder Trainings- und Testdaten. In diesem Beispiel speichern wir die Bilder der handgeschriebenen Ziffern sowie die dazugehörigen Labels in unabhängigen Objekten (also nicht wie bisher in einem einzigen Dataframe).\n",
    "\n",
    "Außerdem speichern wir die Trainings- und Testdaten direkt in zwei Objekten. Wir müssen die Daten später noch weiterverarbeiten, so sind wir aber immer in der Lage, auf die ursprünglichen Daten zuzugreifen, und uns beispielsweise die ursprünglichen Bilder anzuschauen.\n",
    "\n",
    "* `train_images`, `train_labels`, `test_images` und `test_labels` werden wir nachher weiterverarbeiten und unserem neuronalen Netz übergeben.\n",
    "* `tri`, `trl`, `tei` und `tel` können wir uns jederzeit anschauen, wenn wir das ursprüngliche Datenformat abrufen wollen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7d0c5e-b409-49e0-a38b-5fbd6dae9db0",
   "metadata": {
    "id": "9e7d0c5e-b409-49e0-a38b-5fbd6dae9db0"
   },
   "outputs": [],
   "source": [
    "# Load and prepare mnist\n",
    "mnist <- dataset_mnist()\n",
    "\n",
    "# Trainingsdaten zuweisen\n",
    "tri <- train_images <- mnist$train$x\n",
    "trl <- train_labels <- mnist$train$y\n",
    "\n",
    "# Testdaten zuweisen\n",
    "tei <- test_images <- mnist$test$x\n",
    "tel <- test_labels <- mnist$test$y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PCXFYvCF-kwT",
   "metadata": {
    "id": "PCXFYvCF-kwT"
   },
   "source": [
    "#### Wie sehen die MNIST-Daten aus?\n",
    "\n",
    "Jedes Bild aus MNIST ist eine *28x28 pixel grayscale representation* von handgeschriebenen Ziffern. Dieses ist in einem zweidimensionalen Array gespeichert, und je nach Schwärze des Bildes kann jeder Pixel einen Wert zwischen 0 und 255 annehmen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XyhBNYALM4V5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "XyhBNYALM4V5",
    "outputId": "dc597112-6cab-4cdb-9e34-cb9dc165c6db"
   },
   "outputs": [],
   "source": [
    "dim(tei)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Jjp31b-GPwqr",
   "metadata": {
    "id": "Jjp31b-GPwqr"
   },
   "source": [
    "Mithilfe von `dim()` sehen wir direkt, dass es 10.000 Testbilder gibt, welche jeweils die Dimensions 28x28 haben.\n",
    "\n",
    "Das Datenformat, in dem die Bilder vorliegen, wird eindeutiger, wenn wir uns einen einzelnen Bild-Datensatz beispielhaft ausgeben lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RXkS80xM-lDC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXkS80xM-lDC",
    "outputId": "6d2ef6e0-71d8-4c0b-f0ab-2740defc1ee9"
   },
   "outputs": [],
   "source": [
    "options(max.print = 784, width = 784)  # Set a high value so everything gets printed (784 = 28*28 pixel)\n",
    "\n",
    "# this is how the image looks as a matrix representation\n",
    "tei[10,,] %>% print() # print test image number 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ViJnWE85NKxa",
   "metadata": {
    "id": "ViJnWE85NKxa"
   },
   "source": [
    "Na, könnt ihr schon grob erkennen, welche Ziffer angezeigt wird?\n",
    "\n",
    "Alternativ können wir das Bild auch grafisch ausgeben. Dafür konvertieren wir das zweidimensionale Array in ein *raster object*, welches die Bitmap des Bildes repräsentiert. Jeder Pixel der Bitmap kann Werte zwischen 0 und 255 pro Channel annehmen, ein typisches Byte-Format. In diesem Fall haben wir nur einen Channel (*grayscale representation*, es gibt also nur Schwarz als Channel).\n",
    "\n",
    "Im letzten Schritt geben wir das *raster object* mithilfe von `plot()` aus.\n",
    "\n",
    "Welche Ziffer erkennt ihr?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "XCqSR_nZ_Fy8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "XCqSR_nZ_Fy8",
    "outputId": "e42ca48d-ab96-41b7-adfc-6f7c36b63ac0"
   },
   "outputs": [],
   "source": [
    "# this is how the image looks like as a raster representation\n",
    "tei[10,,] %>% as.raster(max = 255) %>% plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iWfLTOlTPr_H",
   "metadata": {
    "id": "iWfLTOlTPr_H"
   },
   "source": [
    "Das können wir schon besser erkennen.\n",
    "\n",
    "* Wie können wir jetzt das zugehörige Label ausgeben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bElGrbhr_Iuy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "bElGrbhr_Iuy",
    "outputId": "a55ea215-fcf4-46b4-c0b2-73382ad6bc63"
   },
   "outputs": [],
   "source": [
    "# and this is it's corresponding label\n",
    "tel[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SgJWkbzy_crU",
   "metadata": {
    "id": "SgJWkbzy_crU"
   },
   "source": [
    "* Lasst euch einige weitere Beispiele ausgeben. Stimmen die Labels immer mit den Bilder überein?\n",
    "* Gebt die Dimensionen des Trainingsdatensatzes aus, um zu überprüfen, wieviele Datenpunkte vorhanden sind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aKVuG5oC_fIr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "aKVuG5oC_fIr",
    "outputId": "4e1352c1-e164-4420-d005-7b3cce9716b1"
   },
   "outputs": [],
   "source": [
    "# Dimensionen der Trainingsdaten\n",
    "tri %>%\n",
    "   dim()\n",
    "\n",
    "# Beispielhaft die Trainingslabels ausgeben\n",
    "trl %>%\n",
    "   glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hAP6ujkG_hqL",
   "metadata": {
    "id": "hAP6ujkG_hqL"
   },
   "source": [
    "#### Daten vorbereiten\n",
    "\n",
    "Jedes Bild besteht aus einem 28 \\* 28 Array. Daher sollte die Input-Größe des neuronalen Netzes aus $28*28=784$ Einheiten bestehen. Das Netz bekommt dann alle Pixel als eindimensionalen Vektor übergeben. Daher müssen wir die Trainings- und Testdaten mithilfe von `array_reshape()` umwandeln.\n",
    "\n",
    "Außerdem wollen wir die Pixelwerte von der Skala zwischen 0 und 255 zu einer standardisierten Skala, die nur noch zwischen von 0 bis 1 variieiert herunterskalieren. Dafür können wir einfach jeden Wert durch 255 teilen.\n",
    "\n",
    "> In diesem Beispiel (ein Feedforward Netzwerk für Klassifizierungsaufgaben) können wir der Einfachheit halber nur eine Dimension für die Datenverarbeitung nutzen. Theoretisch wäre es auch denkbar, das Netzwerk zweidimensional anzulegen - das wird dann komplizierter, würde in einem \"echten\" Anwendungsfall aber vermutlich gemacht werden. Komplexere Netzwerkstrukturen wie z.B. sequenzielle Netzwerke für Textgenerierung oder Sprachverarbeitung nutzen meist sogar dreidimensionale Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "r5D1G3YE8k2D",
   "metadata": {
    "id": "r5D1G3YE8k2D"
   },
   "outputs": [],
   "source": [
    "# reshape the images to one dimensional vectors and scale to a range of [0, 1]\n",
    "train_images <- train_images %>%\n",
    "  array_reshape(c(60000, 28*28)) / 255\n",
    "\n",
    "test_images <- test_images %>%\n",
    "  array_reshape(c(10000, 28*28)) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EyED0UevTiYp",
   "metadata": {
    "id": "EyED0UevTiYp"
   },
   "source": [
    "Als neue Dimension für die Bilder haben wir `c(60000, 28*28)` angegeben. Die einzelnen Bilder bleiben also separiert, jedes Bild besteht jetzt aber aus einem eindimensionalen Array von der Größe $28*28=784$. Das können wir einmal beispielhaft überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641UOyxdTvqj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "id": "641UOyxdTvqj",
    "outputId": "0156d64d-edd7-4f59-c3fb-0683fb57366f"
   },
   "outputs": [],
   "source": [
    "# print the new one-dimensional vector\n",
    "test_images[10,]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jQ6EeMGEUGKg",
   "metadata": {
    "id": "jQ6EeMGEUGKg"
   },
   "source": [
    "> `array_reshape()` sortiert standardmäßig das neue Objekt in einer **column-major order**. Der neue Vektor wird also Spalte nach Spalte aufgefüllt.\n",
    "\n",
    "Außerdem können wir mithilfe von `to_categorical()` unsere Labelobjekte in einen kategorialen Datentyp verwandeln. Sonst weiß das Netzwerk nicht, das es auf Kategorien (und nicht auf kontinuierliche Werte von 0 bis 9) trainiert werden soll!\n",
    "\n",
    "> Diesen Schritt kennen wir bereits aus den anderen ML-Algorithmen - da haben wir für Klassifizierungsprobleme den Datentyp `factor` verwendet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KfqDk_6D8kqv",
   "metadata": {
    "id": "KfqDk_6D8kqv"
   },
   "outputs": [],
   "source": [
    "# convert to categorical labels\n",
    "train_labels <- train_labels %>% to_categorical()\n",
    "test_labels <- test_labels %>% to_categorical()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pVgTXwUoAJJ2",
   "metadata": {
    "id": "pVgTXwUoAJJ2"
   },
   "source": [
    "### Das Neuronale Netzwerk\n",
    "\n",
    "Die Daten sind jetzt für das neuronale Netz vorbereitet!\n",
    "\n",
    "Als nächster Schritt folgt die Definition des Netzwerkes. Für unsere Zwecke wollen wir ein einfaches sequenzielles Netzwerk definieren.\n",
    "\n",
    "Dieses besteht aus einem sogenannten Input-Layer von der Größe $28*28=784$, zwei sogenannten *hidden layers* und einem Output-Layer von der Größe 10. Der Output-Layer hat die Größe 10, weil wir insgesamt 10 verschiedene Ziffern vorhersagen wollen (0 bis 9). Jede Einheit im Output-Layer repräsentiert also einer der Ziffern von 0 bis 9. Das Netzwerk soll uns für jeden dieser Output-Knoten eine Wahrscheinlichkeit vorhersagen, ob es sich bei einem Input um diesen Output handelt oder nicht. Also bspw. \"auf diesem Bild ist mit 93% WAhrscheinlichkeit eine 9 zu sehen\".\n",
    "\n",
    "In unserem Netzwerk ist jedes Neuron in jedem Layer ist mit allen Neuronen in den benachbarten Layern verbunden - es ist also ein \"Fully-Connected Network\". Als Aktivierungsfunktionen für die inneren Layer benutzen die wir ReLU (Rectifier Linear Unit). Das ist eine recht einfache mathematische Funktion, die wenig rechenpower erfordert und mit der wir trotzdem eine gewisse  Nicht-Linearität in das Netzwerk einbauen können. Unser Output-Layer nutzt die sogenannte `softmax`-Funtkion. Diese erzeugt eine Wahrscheinlichkeitsverteilung zwischen allen möglichen Werten, sodass die Summe über alle 10 Outputs hinweg 1 ergibt.\n",
    "\n",
    "Als Maß für die Performance des Netzwerkes benutzen wir den *root mean square error* (angegeben unter `optimizer`). Optimiert wird die `accuracy` des Netzwerkes, also im Prinzip die Genauigkeit, mit der das Netzwerk die Ziffern kategorisiert. Wir kennen diese Maßzahl schon aus früheren Sitzungen. `categorical_crossentropy` nutzen wir als Loss-Function – einfach gesagt ist dies ein Maß, mit dem wir bestimmen können, wie weit unsere Vorhersage vom tatsächlichen Ergebnis entfernt ist.\n",
    "\n",
    "> Vielleicht kommen euch einige Begriffe bereits aus der Vorlesung bekannt vor. Keine Sorge, es geht an dieser Stelle mal wieder nicht darum, alles bis ins kleinste Detail zu verstehen. Wichtiger ist, dass ihr einen Überblick über das Thema erhaltet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428c425b-481b-415f-84eb-dd41428f2e1a",
   "metadata": {
    "id": "428c425b-481b-415f-84eb-dd41428f2e1a"
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "network <- keras_model_sequential() %>%\n",
    "    layer_dense(units = 1000, activation = \"relu\", input_shape = c(28*28)) %>% # input & first hidden layer with 1000 units\n",
    "    layer_dense(units = 1000, activation = \"relu\") %>% # second hidden layer with 1000 units\n",
    "    layer_dense(units = 10, activation = \"softmax\") # output layer with 10 units\n",
    "\n",
    "network %>% compile(\n",
    "  optimizer = \"rmsprop\", # adaptive learning optimizer rmsprop\n",
    "  loss = \"categorical_crossentropy\", # for the loss function we use categorical crossentropy\n",
    "  metrics = c(\"accuracy\") # accuracy is chosen as the performance metric\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ljVmn5RMAVa1",
   "metadata": {
    "id": "ljVmn5RMAVa1"
   },
   "source": [
    "#### Das Netzwerk trainieren\n",
    "\n",
    "Nachdem wir den Datensatz vorbereitet und unser Netzwerk definiert haben, können wir es trainieren.\n",
    "\n",
    "> Achtung: das Training dauert in einer kostenlosen Colab-Laufzeit ca. 2-3 Minuten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f36e747-be95-4b2e-b82e-5f81cd1fced0",
   "metadata": {
    "id": "1f36e747-be95-4b2e-b82e-5f81cd1fced0"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "network %>% fit(\n",
    "  train_images, # Trainingsdaten sowie\n",
    "  train_labels, # die dazugehörigen Labels\n",
    "  epochs = 10, # Anzahl der Trainingsdurchläufe\n",
    "  batch_size = 1000 # die Anzahl der Bilder, die gleichzeitig in das Netzwerk geschickt wird\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dalPnfEoE6g",
   "metadata": {
    "id": "3dalPnfEoE6g"
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Abschließend wollen wir das Netzwerk wieder evaluieren. Dafür nutzen wir die Funktion `evaluate()` aus `keras` und übergeben dem Netzwerk unsere Testdaten und die dazugehörigen Labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526da8c8-7eb0-40ef-b2da-9ebf3a7d8498",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "526da8c8-7eb0-40ef-b2da-9ebf3a7d8498",
    "outputId": "79a60448-f339-4086-8787-3591a4b67eed"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "network %>% evaluate(\n",
    "  test_images,\n",
    "  test_labels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pGvjzS9mBOhs",
   "metadata": {
    "id": "pGvjzS9mBOhs"
   },
   "source": [
    "Als Output erhalten wir zwei verschiedene Measures:\n",
    "\n",
    "* Hohe Genauigkeit (Accuracy) von $>98\\%$: unser Netzwerk erreicht eine hohe Genauigkeit in der Klassifizierung der MNIST-Daten. In über 98% der Fälle erkennt es die richtige Ziffer. Das ist ein sehr gutes Ergebnis!\n",
    "* Geringer Loss ($< 0.1$): das Measure Loss passt gut zu unserer hohen Genauigkeit. Es ist etwas schwieriger zu erklären, aber im Prinzip sagt uns dieser Wert, wie nahe die vom Modell vorhergesagte Wahrscheinlichkeitsverteilung im Output-Layer an das tatsächliche Ergebnis der Trainingsdaten herankommt.\n",
    "\n",
    "> Achtung: wir haben in unserem spezifischen Fall eine sehr hohe Genauigkeit erreicht. Wie bei jedem ML-Problem ist es aber wichtig, sich klar zu machen, dass es immer die Gefahr des Overfittings gibt. Vielleicht hat unser Netzwerk jetzt sehr gut gelernt, die Trainingsdaten vorherzusagen – ob es in der \"echten Welt\" dann noch gut bestehen würde, ist dadurch nicht automatisch gegeben! In der Realität gibt es weitere Techniken, um Overfitting zu vermeiden, wie beispielsweise *cross-validation*, *regularisation*, *diverse trainings sets*, etc. Auf diese werden wir hier allerdings nicht genauer eingehen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_lGw0uE-pTI6",
   "metadata": {
    "id": "_lGw0uE-pTI6"
   },
   "source": [
    "Wie können wir uns die Evaluation noch etwas genauer anschauen?\n",
    "\n",
    "Wir können mithilfe von `predict()` die Testbilder vorhersagen und mit den ursprünglichen `test_labels` vergleichen. Dann können wir uns anschauen, bei welchen Bildern das Modell eine falsche Vorhersage getroffen hat.\n",
    "\n",
    "Dafür klassifizieren wir die Testbilder einmal mithilfe von `predict()` und vergleichen diese anschließend mit den tatsächlichen Labels.\n",
    "\n",
    "Wenn wir die Testbilder von `predict()` vorhersagen, erhalten wir pro Bild das Ergebnis des Output-Layers (also ein Ergebnis für jede der 10 Ziffern). Der jeweils größte Wert ist der, den das Netzwerk für am wahrschenilichsten hält und den man in einer automatisierten Entschiedungsfindung wählen würde. Den  Index der wahrschneilchten Ziffer finden wir mithilfe von `k_argmax(axis = -1)`.\n",
    "\n",
    "Dieses Ergebnis wird uns als Tensor zurückgegeben, welchen wir mit `k_eval()` dann wieder in ein bekanntes R-Array ausgeben können.\n",
    "\n",
    "> Falls das gerade zu kompliziert ist, führt den Code einfach gerne aus und freut euch daran, dass es funktioniert :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6OnEZoqKpvVQ",
   "metadata": {
    "id": "6OnEZoqKpvVQ"
   },
   "outputs": [],
   "source": [
    "predicted_labels <- network %>% predict(test_images) %>% # make predictions\n",
    "  k_argmax(axis = -1) %>% k_eval() # convert predictions to class labels\n",
    "\n",
    "processed_test_labels <- test_labels %>%\n",
    "  k_argmax(axis = -1) %>% k_eval() # convert test labels to class labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IsjCi8uQZWTD",
   "metadata": {
    "id": "IsjCi8uQZWTD"
   },
   "source": [
    "Ansschließend können wir die vorhergesagten und die tatsächlichen Labels mithilfe von `which()` vergleichen und uns die Indizes ausgeben lassen, die nicht korrekt vorhergesagt wurden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RBqgH73fZV7K",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RBqgH73fZV7K",
    "outputId": "05097d05-f03e-4260-86ba-b9fc86b4b614"
   },
   "outputs": [],
   "source": [
    "incorrect_indices <- which(predicted_labels != processed_test_labels) # Find the indices of incorrect predictions\n",
    "\n",
    "incorrect_indices %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efLF0TJ4Zgtp",
   "metadata": {
    "id": "efLF0TJ4Zgtp"
   },
   "source": [
    "Beispielhaft können wir einmal für den ersten inkorrekt vorhergesagten Index das Testbild und den vorhergesagten Index ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mJ6PSBcPZhJU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 492
    },
    "id": "mJ6PSBcPZhJU",
    "outputId": "78369bfc-205d-41e0-c192-176180fb2215"
   },
   "outputs": [],
   "source": [
    "# Print details about the first incorrect example\n",
    "cat(\"First incorrect example at index:\", incorrect_indices[1], \"\\n\")\n",
    "cat(\"Predicted label:\", predicted_labels[incorrect_indices[1]], \"\\n\")\n",
    "cat(\"Actual label:\", processed_test_labels[incorrect_indices[1]], \"\\n\")\n",
    "\n",
    "tei[incorrect_indices[1],,] %>% as.raster(max = 255) %>% plot() # Print the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cMCTRMxnq3At",
   "metadata": {
    "id": "cMCTRMxnq3At"
   },
   "source": [
    "Wir können uns für diesen Index nochmal den Output des Netzwerkes anzeigen lassen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "L9bBulqJq8HH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "L9bBulqJq8HH",
    "outputId": "3eddae1d-b1ae-4bb7-fd97-4ec70f9796bd"
   },
   "outputs": [],
   "source": [
    "wrong_prediction <- network %>% predict(test_images)\n",
    "wrong_prediction[incorrect_indices[1],]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_P3AP_PZsWzq",
   "metadata": {
    "id": "_P3AP_PZsWzq"
   },
   "source": [
    "Wie wir sehen können, ist die Wahrscheinlichkeit für die Ziffer 2 (der 3. Index Liste) ähnlich hoch wie die Wahrscheinlichkeit für die Ziffer 4 (der 5. Index der Liste). Das Netzwerk liegt also nur knapp daneben!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hSSDC3a6q3I_",
   "metadata": {
    "id": "hSSDC3a6q3I_"
   },
   "source": [
    "* Könnt ihr nachvollziehen, dass das Netzwerk in diesem Fall Schwierigkeiten hatte, die korrekte Ziffer zu identifizieren?\n",
    "* Gebt 2-3 weitere falsch vorhergesagte Bilder aus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OujY3qmAtdDH",
   "metadata": {
    "id": "OujY3qmAtdDH"
   },
   "source": [
    "#### Eigene handschriftliche Bilder erkennen\n",
    "\n",
    "Jetzt wollen wir unser neuronales Netzwerk mal mit einem Bild testen, welches wir selber hochgeladen haben.\n",
    "\n",
    "Wenn ihr auf das Ordnersymbol in der linken Symbolleiste in Colab klickt, öffnet sich das aktuelle Arbeitsverzeichnis.\n",
    "\n",
    "> Achtung: dieses Verzeichnis ist temporärer Natur und wird jedes Mal gelöscht, wenn ihr das Colab-Notebook in einer neuen Laufzeit öffnet (also z.B. wenn ihr euren Computer zwischendurch ausgeschaltet oder euch ausgeloggt habt).\n",
    "\n",
    "Per Drag & Drop oder über das Hochladen-Symbol könnt ihr eine Datei hochladen.\n",
    "\n",
    "Wenn ihr wollt, könnt ihr ein eigenes Bild mit eurem Handy machen und dieses hochladen. Das Bild sollte in einem quadratischen Format in einem gängigen Dateityp (z.B. jpg, png) vorliegen. Am besten schraubt ihr die Belichtung und den Kontrast vorher hoch, damit das Bild bereits möglichst schwarz-weiß vorliegt!\n",
    "\n",
    "Wenn ihr kein eigenes Bild benutzen wollt oder könnt, könnt ihr auch die Dateien aus dem Ordner `dw1/data/images/` benutzen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BwXhMAjvxJ18",
   "metadata": {
    "id": "BwXhMAjvxJ18"
   },
   "source": [
    "Als erstes wollen wir das Bild laden und einmal ausgeben lassen. Dafür können wir uns eine eigene kleine Funktion `load_image()` schreiben, die das Preprocessing übernimmt (also die vorbereitung des Bildes für die Datenanalyse). Unsere Funktion benutzt dazu verschiedene Funktionen aus dem Paket `magick`.\n",
    "\n",
    "* Das Bild lesen mit `image_read(image_path)`\n",
    "* Das Bild in *gray scale* konvertieren mit `image_convert(colorspace = 'gray')`\n",
    "* Das Bild auf 28*28 Pixel skalieren mit `image_resize('28x28!')`\n",
    "* Das Bild invertieren mit `image_negate()`, damit es zu den bisherigen MNIST-Bildern passt und weiß auf schwarz angezeigt wird.\n",
    "\n",
    "Wir laden das Bild und können es anschließend wie weite oben mit `as.raster()` plotten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GjLO1OZwwWj_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 437
    },
    "id": "GjLO1OZwwWj_",
    "outputId": "7c5378a9-45a6-4669-c294-d9e898ed8f5d"
   },
   "outputs": [],
   "source": [
    "load_image <- function(image_path) {\n",
    "  image <- image_read(image_path) %>%\n",
    "    image_convert(colorspace = 'gray') %>%\n",
    "    image_resize('28x28!') %>%\n",
    "    image_negate()\n",
    "\n",
    "  return(image)\n",
    "}\n",
    "\n",
    "# Example usage\n",
    "image_path <- \"one.jpg\"\n",
    "loaded_image <- load_image(image_path) # load the image\n",
    "loaded_image %>%\n",
    "    as.raster() %>%\n",
    "    plot() # plot the image as raster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "POTOV8XHx3Fx",
   "metadata": {
    "id": "POTOV8XHx3Fx"
   },
   "source": [
    "Jetzt wo wir das Bild geladen haben, müssen wir es weiterverarbeiten:\n",
    "\n",
    "Analog zu den Trainings- und Testbildern muss das Bild als eindimensionaler Vektor der Länge $28*28=784$ und einzelnen Datenpunkten zwischen 0 und 1 vorliegen, damit es von unserem neuronalen Netz verarbeitet werden kann.\n",
    "\n",
    "Wir konvertieren also als nächstes unser Bild in ein eindimensionales Array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HWP0yDa2zGdH",
   "metadata": {
    "id": "HWP0yDa2zGdH"
   },
   "outputs": [],
   "source": [
    "image_to_array <- function(loaded_image) {\n",
    "  image_data <- image_data(loaded_image) # Extract image data\n",
    "\n",
    "  image_vector <- image_data[1,,] %>% # Select the first layer of the bitmap\n",
    "    as.integer() / 255 # Convert from raw hexadecimal to integer and normalise to values between 0 and 1\n",
    "\n",
    "  return(image_vector)\n",
    "}\n",
    "\n",
    "image_array <- image_to_array(loaded_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OkcO2FFA2bfF",
   "metadata": {
    "id": "OkcO2FFA2bfF"
   },
   "source": [
    "Wir können uns das geladene `image_array` einmal ausgeben lassen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zm0iXfJp2bOK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zm0iXfJp2bOK",
    "outputId": "f8612914-1684-45f9-9f20-1170a95bcdad"
   },
   "outputs": [],
   "source": [
    "image_array %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3au2W9F1bh_8",
   "metadata": {
    "id": "3au2W9F1bh_8"
   },
   "source": [
    "Anschließend müssen wir das neue Bild ganauso wie unsere Trainings-/Testdaten mithilfe von `array_reshape()` an den Input-Layer des Netzwerkes anpassen.\n",
    "Dann können wir es mit `predict()` vorhersagen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83nfUJspx2eR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83nfUJspx2eR",
    "outputId": "cffebc48-e55e-4bbe-8929-47bddb967866"
   },
   "outputs": [],
   "source": [
    "# Reshape Array\n",
    "image_array_reshaped <- array_reshape(image_array, c(1, 784))\n",
    "\n",
    "# Predict with the previously trained model\n",
    "prediction <- network %>% predict(image_array_reshaped)\n",
    "prediction %>% print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1n6YZxFCb0FD",
   "metadata": {
    "id": "1n6YZxFCb0FD"
   },
   "source": [
    "Hoppla, da bekommen wir ja wieder 10 Werte heraus! Das liegt daran, dass wir mit `predict()` wieder einfach den Output-Layer des Netzwerkes ausgegeben haben.\n",
    "\n",
    "Wir nehmen also den Index, der am größten ist, und ziehen nochmal 1 davon ab, da die Indizes 1-10 ja den Ziffern 0-9 entsprechen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "H37nzWdzb0XR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H37nzWdzb0XR",
    "outputId": "f045a299-3a63-4593-efc1-366da8b79168"
   },
   "outputs": [],
   "source": [
    "# Print which output unit has the highest output (subtract 1 to scale it to the numbers 0 to 9)\n",
    "print(paste(\"Predicted label:\", which.max(prediction) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "psl_i0Fo5-Kv",
   "metadata": {
    "id": "psl_i0Fo5-Kv"
   },
   "source": [
    "Hoffentlich hat das jetzt gerade funktioniert! Wenn ihr Dateien aus dem Ordner `dw1/data/images/` genommen habt, sollte es auf jeden Fall geklappt haben.\n",
    "\n",
    "Wenn wir die ausgeführten Schritte jetzt noch an weiteren Beispielen testen wollen, lohnt es sich eventuell, eine neue Funktion zu schreiben, die die Schritte kombiniert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wx0RMZTt3Gry",
   "metadata": {
    "id": "wx0RMZTt3Gry"
   },
   "outputs": [],
   "source": [
    "# function to recognize a handwritten number\n",
    "predict_number <- function(image_path) {\n",
    "  loaded_image <- load_image(image_path) # load the image\n",
    "  loaded_image %>% as.raster() %>% plot() # plot the image as raster\n",
    "\n",
    "  image_array <- image_to_array(loaded_image)\n",
    "  image_array_reshaped <- array_reshape(image_array, c(1, 784))\n",
    "\n",
    "  prediction <- network %>% predict(image_array_reshaped)\n",
    "  print(paste(\"Predicted label:\", which.max(prediction) - 1))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JSz6jf2C6Wij",
   "metadata": {
    "id": "JSz6jf2C6Wij"
   },
   "source": [
    "* Testet die Funktion an einem weiteren eigenen Beispiel oder einem Beispielbild aus dem DW1-Ordner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "z_nUT_-o3GpT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 454
    },
    "id": "z_nUT_-o3GpT",
    "outputId": "e4a27692-6d15-4097-b676-70ad0fa00c6b"
   },
   "outputs": [],
   "source": [
    "predict_number(\"seven.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KluGfG_crN8r",
   "metadata": {
    "id": "KluGfG_crN8r"
   },
   "source": [
    "## Optional: Network weights\n",
    "\n",
    "Wenn ihr jetzt noch Zeit habt, könnt ihr einmal die Parameter des Netzwerkes ausgeben lassen. Das macht man in `keras` mithilfe von `get_weights()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5skkYVrO7P",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ce5skkYVrO7P",
    "outputId": "4595796e-8ece-4df9-96c6-eb8a869a3d24"
   },
   "outputs": [],
   "source": [
    "parameters = network %>% get_weights()\n",
    "parameters %>% glimpse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QfHc0A_u9GI9",
   "metadata": {
    "id": "QfHc0A_u9GI9"
   },
   "source": [
    "Leider sind diese nicht direkt beschriftet, sie werden aber in der Reihenfolge der vorher definiert Layers ausgegeben! In unserem Beispiel haben wir zwei Parameter pro Layer, einmal die **Weights** und die **Biases**. An erster Stelle werden immer die Weights ausgegeben, danach die Biases. Das könnt ihr auch anhand der Dimensionen jeder einzelnen Zeilen nachvollziehen (es gibt pro Layer nur so viele Biases, wie es Einheiten gibt; und pro Layer so viele Weights, wie es Verbindungen zu den benachbarten Layers gibt).\n",
    "\n",
    "Wir können an dieser Stelle auch die Anzahl der Parameter unseres Netzwerkes berechnen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iESNYut09MSO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iESNYut09MSO",
    "outputId": "b5b4135a-f2e4-4864-f225-e3583c1f7160"
   },
   "outputs": [],
   "source": [
    "total_parameters = sum(sapply(parameters, function(x) prod(dim(x))))\n",
    "cat(\"The number of total parameters of our network is:\", total_parameters, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TrHGxwBa-oWK",
   "metadata": {
    "id": "TrHGxwBa-oWK"
   },
   "source": [
    "Das ergibt Sinn. Wir können diese Zahl auch selber nochmal nachrechnen:\n",
    "\n",
    "Alle Einheiten pro Layer sind immer mit allen Einheiten im benachbarten Layer verbunden.\n",
    "\n",
    "* Vom 1. Layer (784 Inputs) zum 2. Layer (1000 Einheiten) gibt es $784*1000=784.000$ Verbindungen\n",
    "* Vom 2. Layer (1000 Einheiten) zum 3. Layer (1000 Einheiten) gibt es $1000*1000=1.000.000$ Verbindungen\n",
    "* Vom 3. Layer (1000 Einheiten) zum 4. Layer (10 Einheiten) gibt es $1000*10=10.000$ Verbindungen\n",
    "* Außerdem hat jede Einheit noch einen Bias, wodurch nochmal $1000+1000+10=2.010$ Parameter hinzukommen.\n",
    "\n",
    "Insgesamt macht das 1.796.010 Parameter!\n",
    "\n",
    "Auf dieser Basis lässt sich leicht nachvollziehen, dass beim Training von neuronalen Netzen eine hohe Rechenleistung benötigt wird. Das Netzwerk trainiert, in dem es diese Parameter für jedes Trainings-Bild in mehreren Epochen (in unserem Beispiel waren es 10) forwärts und rückwärts immer weiter optimiert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5Us-46CzzXU6",
   "metadata": {
    "id": "5Us-46CzzXU6"
   },
   "source": [
    "## Zusammenfassung\n",
    "\n",
    "In dieser Sitzung haben wir ein einfaches neuronales Netzwerk in `keras` und `tensorflow` zur Klassifizierung von handschriftlichen Ziffern programmiert und an eigenen Beispielen getestet! Auch wenn es an mancher Stelle etwas kompliziert wurde, habt ihr jetzt hoffentlich ein besseres Verständnis von der grundlegenden Struktur neuronaler Netzwerke.\n",
    "\n",
    "Ein gutes Buch zum Thema Deep Learning ist beispielsweise\n",
    "\n",
    "> Chollet, F., Kalinowski, T. & Allaire, J. J. (2022). Deep learning with R. Manning.\n",
    "\n",
    "### Vergleich zu GPT4\n",
    "\n",
    "Um die Komplexität aktueller neuronaler Netzwerkarchitekturen zu verstehen, können wir unser Modell noch mit dem aktuellen GPT-4 von OpenAI vergleichen.\n",
    "\n",
    "unser MNIST-Netzwerk:\n",
    "- 4 layers\n",
    "- ~1.8 million parameters\n",
    "- 60.000 training tokens\n",
    "\n",
    "\n",
    "GPT-4 ([Quelle](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/)):\n",
    "- 120 layers\n",
    "- ~1.8 trillion (10^12) parameters\n",
    "- ~13 trillion tokens\n",
    "- Training cost of 63 million USD\n",
    "\n",
    "Nach Schätzungen spricht ein Mensch bis zu eine halbe Milliarde Wörter in seinem gesamten Leben [Quelle](https://sz-magazin.sueddeutsche.de/gesellschaft-leben/wir-muessen-reden-77405). GPT-4 ist auf der 26-fachen Menge trainiert. Und die Tendenz ist steigend - die GPT-Modelle wurden in den letzten Jahren fast jährlich aktualisiert, und jedes Mal stieg die Anzahl der Trainingstoken um einen Faktor von 2 bis 3 Stellen [Quelle](https://en.wikipedia.org/wiki/GPT-2).\n",
    "\n",
    "|                 | Unser MNIST-Modell   | GPT-4        | Faktor GPT-4 vs. unser Modell |\n",
    "|----------       |----------   |----------    |----------|\n",
    "| Layers          | 4           | 120          | $30$ |\n",
    "| Parameters      | 1.8 million | ~1.8 trillion | $10^6$ |\n",
    "| Training tokens | 60.000      | ~13 trillion | $2.1 \\times 10^8$ |\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
